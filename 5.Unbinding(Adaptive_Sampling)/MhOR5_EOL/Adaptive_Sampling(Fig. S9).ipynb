{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdbcbf-5bdb-4efa-bd60-6b35563dda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plumed\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "import pandas as pd\n",
    "import random\n",
    "from deeptime.decomposition import TICA\n",
    "from deeptime.covariance import KoopmanWeightingEstimator\n",
    "from deeptime.clustering import MiniBatchKMeans\n",
    "from deeptime.markov import TransitionCountEstimator\n",
    "from deeptime.markov.msm import MaximumLikelihoodMSM\n",
    "from deeptime.plots import plot_implied_timescales\n",
    "from deeptime.util.validation import implied_timescales\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from numpy.random import multinomial\n",
    "import subprocess\n",
    "import os\n",
    "import math\n",
    "from scipy.stats import pearsonr,chisquare\n",
    "import warnings\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1172a6-ee66-4067-b4cd-12f54c713941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure files\n",
    "whole_xtc = './Conf/traj_comp.xtc'\n",
    "whole_gro = './Conf/step7.gro'\n",
    "whole_tpr = './Conf/step7.tpr'\n",
    "gmx = 'docker run --gpus all --rm -e CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps -e CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log --rm --gpus all -v $PWD:/workdir -v /tmp/nvidia-mps:/tmp/nvidia-mps -v /tmp/nvidia-log:/tmp/nvidia-log --ipc host -w /workdir registry.cn-hangzhou.aliyuncs.com/linjiahao/gromacs:2023-plumed-avx2-u2204-cu124 gmx'\n",
    "\n",
    "# RUN setup \n",
    "round = 1\n",
    "total_round = 2\n",
    "start = 40\n",
    "end = 51\n",
    "ligand_number = 4\n",
    "ligand_ids = [474,475,476,477] #No. in tpr\n",
    "pocket_ids = [91,151,154,155,158,213,380,383] #No. in tpr\n",
    "chain_ids = ['A','B','C','D']\n",
    "# TICA parameters (for adaptive sampling)\n",
    "tica_lagtime = 500\n",
    "dim = None\n",
    "var_cutoff = 0.95\n",
    "koopman = True\n",
    "runtICA_njobs = 12\n",
    "# Implied time scale evaluation\n",
    "its_lagtimes = [1,2,5,10,20,35,50,100,200,500]\n",
    "tica_its_lagtimes = [1,2,5,10,20,35,50,100,200,500]\n",
    "n_its = 5\n",
    "# Markov State Model parameters\n",
    "msm_lagtime = 500\n",
    "# PCCA parameters\n",
    "n_metastable_sets = 30\n",
    "seed_num = 12\n",
    "assignments = []\n",
    "seed_idx = []\n",
    "num_cvs = 2\n",
    "\n",
    "patience = 2\n",
    "convergence_criteria = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151dc23-9279-49a0-b828-1edc1fe9a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICA functions         \n",
    "def read_features(round,start,end,seed_num,chain_ids,tica_lagtime,supplement):\n",
    "    # traj is the time-series COLVAR in pandas.DataFrame format\n",
    "    data = []\n",
    "    traj = []\n",
    "    for i in range(1,round+1):\n",
    "        if i != 1:\n",
    "            start = 0\n",
    "            end = seed_num-1\n",
    "        for split in range(start,end+1):\n",
    "            for chain in chain_ids:\n",
    "                try:\n",
    "                    load = plumed.read_as_pandas(f'./CV/COLVAR_round{i}_split{split}_chain{chain}')\n",
    "                    load = load.drop(columns=['time'])\n",
    "                    columns = list(load.columns.values)\n",
    "                    # Remove all dihedral angles, only keep sin/cos dihedrals \n",
    "                    for column in columns:\n",
    "                        if column[:3] == 'phi' or column[:3] == 'psi' or column[:3] == 'chi' or column[:5] == 'omega':\n",
    "                            load = load.drop(columns=[column])\n",
    "                    if len(load) > 1.6*tica_lagtime:\n",
    "                        traj.append(load)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # data is the time-series COLVAR in numpy.ndarrays format\n",
    "    for i in range(len(traj)):\n",
    "        numpy_data = traj[i].to_numpy(dtype='float32')\n",
    "        data.append(numpy_data)\n",
    "    n_features = len(data[0][0])\n",
    "    time_length = len(data[0])\n",
    "    # data = np.array(data)\n",
    "    data_supp = []\n",
    "    if supplement:\n",
    "        for i in range(2,round+1):\n",
    "            if round != 1:\n",
    "                round_seed_idx = np.loadtxt(f'Seed/round{i}_seed.txt')\n",
    "        \n",
    "                for i,round_seed_idx_i in enumerate(round_seed_idx):\n",
    "                    sim_i = int(round_seed_idx_i[0])\n",
    "                    frame = int(round_seed_idx_i[1])\n",
    "                    for chain_id in range(len(chain_ids)):\n",
    "                        if frame == 0:\n",
    "                            continue\n",
    "                        elif tica_lagtime > frame:\n",
    "                            data_supp_pre = data[sim_i*len(chain_ids)-len(chain_ids)+chain_id][:frame,:]\n",
    "                            data_supp_post = data[end-start+1+(round-2)*seed_num+i][:tica_lagtime,:]\n",
    "                        else :\n",
    "                            data_supp_pre = data[sim_i*len(chain_ids)-len(chain_ids)+chain_id][frame -tica_lagtime+1:frame,:]\n",
    "                            data_supp_post = data[end-start+1+(round-2)*seed_num+i][:tica_lagtime,:]\n",
    "                    \n",
    "                       \n",
    "                        data_supp_i = np.concatenate([data_supp_pre,data_supp_post])\n",
    "                        data_supp.append(data_supp_i)\n",
    "                            \n",
    "\n",
    "    return data,traj,data_supp\n",
    "def run_TICA(data,data_supp,lagtime,dim=None,var_cutoff=None):\n",
    "    data_syn = data + data_supp\n",
    "    tica = TICA(lagtime=lagtime,dim=dim,var_cutoff=var_cutoff)\n",
    "    try:\n",
    "        koopman_estimator = KoopmanWeightingEstimator(lagtime=lagtime)\n",
    "        reweighting_model = koopman_estimator.fit(data_syn).fetch_model()\n",
    "        tica = tica.fit(data_syn, weights=reweighting_model).fetch_model()\n",
    "    except:\n",
    "        print('Can\\'t perform Koopman Reweighting TICA, try normal TICA')\n",
    "        tica = tica.fit(data_syn).fetch_model()\n",
    "    tica_output = tica.transform(data)\n",
    "    tica_output_concat = np.concatenate(tica_output)\n",
    "    tica_output_supp = []\n",
    "    for data_supp_i in data_supp:\n",
    "        tica_output_supp_i = tica.transform(data_supp_i)\n",
    "        tica_output_supp.append(tica_output_supp_i)\n",
    "    return tica,tica_output,tica_output_concat,tica_output_supp\n",
    "    \n",
    "def calculate_nmicro(data_concat):\n",
    "    n_microstates = int(max(100, np.round(0.6 * np.log10(data_concat.shape[0] / 1000) * 1000 + 50)))\n",
    "    return n_microstates\n",
    "    \n",
    "def run_kmeans(tica_output,tica_output_concat,tica_output_supp,n_microstates,n_jobs):\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=n_microstates,batch_size=10000,max_iter=100,init_strategy='kmeans++',n_jobs=n_jobs)\n",
    "    microstates = minibatch_kmeans.fit(tica_output_concat).fetch_model()\n",
    "    assignments_concat = microstates.transform(tica_output_concat)\n",
    "    assignments = assignments_concat.reshape(-1,tica_output.shape[1])\n",
    "    assignments_supp = []\n",
    "    for tica_output_supp_i in tica_output_supp:\n",
    "        assignments_supp_i = microstates.transform(tica_output_supp_i)\n",
    "        assignments_supp.append(assignments_supp_i)\n",
    "    return assignments,assignments_concat,assignments_supp\n",
    "\n",
    "def evaluate_its(lagtimes,n_its,round):\n",
    "    models = []\n",
    "    for lagtime in lagtimes:\n",
    "        counts = TransitionCountEstimator(lagtime=lagtime, count_mode='sliding').fit_fetch(assignments.reshape(-1,tica_output.shape[1]))\n",
    "        models.append(MaximumLikelihoodMSM().fit_fetch(counts))\n",
    "        its_data = implied_timescales(models)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_implied_timescales(its_data, n_its=n_its, ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('Implied timescales')\n",
    "    ax.set_xlabel('lag time (steps)')\n",
    "    ax.set_ylabel('timescale (steps)')\n",
    "    plt.savefig(f'./figures/its-round{round}.png',dpi=600)\n",
    "    return None\n",
    "\n",
    "def evaluate_tica_its(tica_its_lagtimes,dim,var_cutoff,koopman,n_its,round):\n",
    "    tica_models = []\n",
    "    for lag in tica_its_lagtimes:\n",
    "        tica = run_TICA(data,lag,dim,var_cutoff,koopman)[0]\n",
    "        tica_models.append(tica)\n",
    "    its_data = implied_timescales(tica_models)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_implied_timescales(its_data, n_its=n_its, ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('Implied timescales')\n",
    "    ax.set_xlabel('lag time (steps)')\n",
    "    ax.set_ylabel('timescale (steps)')\n",
    "    plt.savefig(f'./figures/tica-its-round{round}.png',dpi=600)\n",
    "    return None\n",
    "    \n",
    "def build_MSM(msm_lagtime,assignments,assignments_supp):\n",
    "    assignments_syn = list(assignments)+assignments_supp\n",
    "    counts = TransitionCountEstimator(lagtime=msm_lagtime, count_mode='sliding').fit_fetch(assignments_syn)\n",
    "    msm = MaximumLikelihoodMSM().fit_fetch(counts)\n",
    "    return counts,msm\n",
    "    \n",
    "def run_PCCA(msm,n_metastable_sets):\n",
    "    pcca = msm.pcca(n_metastable_sets=n_metastable_sets)\n",
    "    return pcca\n",
    "\n",
    "### Adaptive seeding functions\n",
    "def fix_disconnected(counts,n_microstates,msm,pcca):\n",
    "    sets = counts.connected_sets(connectivity_threshold=0,directed=True,sort_by_population=True)\n",
    "    disconnected_sets = sets[1:]\n",
    "    n_macro_disconnected = len(disconnected_sets)\n",
    "    disconnected_dict = {}\n",
    "    for i in range(n_macro_disconnected):\n",
    "        macro_label = n_metastable_sets + i\n",
    "        for j in disconnected_sets[i]:\n",
    "            disconnected_dict[j] = macro_label\n",
    "    pcca_assignments = np.zeros(n_microstates,dtype=int)\n",
    "    stationary_distribution = np.zeros(n_microstates,)\n",
    "\n",
    "    connected_count = 0\n",
    "    for i in range(n_microstates):\n",
    "        if i in disconnected_dict.keys():\n",
    "            pcca_assignments[i] = disconnected_dict[i]\n",
    "            stationary_distribution[i] = 0\n",
    "        else:\n",
    "            pcca_assignments[i] = pcca.assignments[connected_count]\n",
    "            stationary_distribution[i] = msm.stationary_distribution[connected_count]\n",
    "            connected_count += 1\n",
    "        \n",
    "    return n_macro_disconnected,pcca_assignments,stationary_distribution\n",
    "    \n",
    "#maybe it is not correct    \n",
    "def count_macro(seed_num,n_macro_disconnected,pcca_assignments,assignments_concat,round):\n",
    "    macro_assignments = dict(enumerate(pcca_assignments))\n",
    "    macro_timeseries = np.vectorize(macro_assignments.get)(assignments_concat)\n",
    "    # Macrostate seeding\n",
    "    unique_macro, counts_macro = np.unique(macro_timeseries, return_counts=True)\n",
    "    prob_macro = (1 / counts_macro) / np.sum(1 / counts_macro)\n",
    "    macrostate_seed = multinomial(seed_num,prob_macro)\n",
    "\n",
    "    # Microstate seeding\n",
    "    # First count the occurences of all microstates\n",
    "    unique_micro, counts_micro = np.unique(assignments_concat, return_counts=True)\n",
    "    seed_idx = []\n",
    "    counts_micro_i_log = {}\n",
    "    for macro_i, n_sample in enumerate(macrostate_seed):\n",
    "        # locate the index of microstates not assigned to current selected macrostates\n",
    "        not_macro_idx = np.where(pcca_assignments != np.unique(pcca_assignments)[macro_i])\n",
    "        # let all entries corresponding to not_macro_idx = 0, therefore ignore them during selection\n",
    "        counts_micro_i = deepcopy(counts_micro)\n",
    "        counts_micro_i[not_macro_idx] = 0\n",
    "        # let 1/0 = 0\n",
    "        inverse_counts = np.where(counts_micro_i==0, 0, 1/counts_micro_i)\n",
    "        prob_micro_i = inverse_counts / np.sum(inverse_counts)\n",
    "        microstate_seed = multinomial(n_sample,prob_micro_i)\n",
    "        # Record selection statistics for visualization\n",
    "        if n_sample != 0:\n",
    "            macro_idx_log = unique_macro[macro_i] \n",
    "            counts_micro_i_log[macro_idx_log] = [counts_micro_i,microstate_seed]\n",
    "        for micro_i, n_sample in enumerate(microstate_seed):\n",
    "            seed_idx = seed_idx + n_sample * [micro_i]\n",
    "    return seed_idx\n",
    "#below need to refine\n",
    "def write_gmxfile(round,start,end,seed_num,whole_gro,assignments,seed_idx,dumpseed=True):\n",
    "    ### .gro seed files generation\n",
    "    conf_seed = []\n",
    "    if dumpseed:\n",
    "        last_round = round\n",
    "        round += 1\n",
    "        !mkdir round{round}_unbiased\n",
    "        u_list = []\n",
    "        for round_i in range(1,round):\n",
    "            if round_i != 1:\n",
    "                start = 0\n",
    "                end = seed_num-1\n",
    "            for i in range(start,end+1):\n",
    "                u_traj = mda.Universe(whole_gro,f'./round{round_i}_unbiased/split_{i}.xtc')\n",
    "                u_list.append(u_traj)\n",
    "        conf_seed = []\n",
    "    \n",
    "        for i,seed in enumerate(seed_idx):\n",
    "            conf_idx = np.array(np.where(assignments==seed)).T\n",
    "            conf_seed_frame = conf_idx[np.random.randint(conf_idx.shape[0], size=1), :][0]\n",
    "            conf_seed_frame[0] = math.ceil((conf_seed_frame[0]+1)/4)-1\n",
    "            conf_seed.append(conf_seed_frame)\n",
    "    \n",
    "        for i,seed in enumerate(conf_seed):\n",
    "            traj_no = seed[0]\n",
    "            frame = seed[1]\n",
    "            u_list[traj_no].atoms.write(f'./round{round}_unbiased/split_{i}.gro',frames=u_list[traj_no].trajectory[frame:frame+1])\n",
    "        \n",
    "        np.savetxt(f'./Seed/round{round}_seed.txt',conf_seed,fmt='%s')\n",
    "        \n",
    "    with open(f'./round{round}_unbiased/run.sh','w') as f:\n",
    "        f.writelines(f'gmx={gmx}\\n')\n",
    "        f.writelines(f'start={start}\\n')\n",
    "        f.writelines(f'end={end}\\n')\n",
    "        f.writelines('for i in `seq $start $end`\\n')\n",
    "        f.writelines('do\\n')\n",
    "        f.writelines(f'    $gmx grompp -f ./Conf/step7_production.mdp -p ./Conf/topol.top -c ./round{round}_unbiased/split_$i.gro -o ./round{round}_unbiased/split_$i.tpr -n ./Conf/index.ndx \\n')\n",
    "        f.writelines(f'    $gmx mdrun -deffnm ./round{round}_unbiased/split_$i -ntmpi 1 -ntomp 20 -nb gpu -pme gpu -pmefft gpu -bonded gpu -gpu_id 0 -cpi -v -pin on -update gpu\\n')\n",
    "        f.writelines('done\\n')\n",
    "        \n",
    "    return round,conf_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971e4dc-d0cb-45ef-9ad4-8c37891b8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine learning CV related functions\n",
    "def tica_cv_print(feature_dats,traj,tica,num_cvs,chain_ids,round,start,end,seed_num,driver=True):\n",
    "    traj_concat = pd.concat(traj,axis=0)\n",
    "    lines = []\n",
    "    for feature_dat in feature_dats:\n",
    "        with open(feature_dat,'r') as g:\n",
    "            line = g.readlines()\n",
    "        lines.append(line)\n",
    "    for i in range(1,round+1):\n",
    "        if i != 1:\n",
    "            start = 0\n",
    "            end = seed_num-1\n",
    "        for split in range(start,end+1):\n",
    "            for chaini in range(len(chain_ids)):\n",
    "                with open(f'./tica-cv/tica-driver_round{i}_chain{chain_ids[chaini]}.dat','w') as f:\n",
    "                    f.writelines('MOLINFO STRUCTURE=./Conf/step7.pdb\\n')\n",
    "                    for line in lines[chaini][1:-1]:   # remove PRINT argument\n",
    "                        f.writelines(line)\n",
    "                    arg_string = ''\n",
    "                    parameters_string = ''\n",
    "                    for fi, feature in enumerate(traj[chaini].columns):\n",
    "                        arg_string = arg_string + feature + ','\n",
    "                        parameters_string = parameters_string + str(tica.mean_0[fi]) + ','\n",
    "                    arg_string = arg_string[:-1]\n",
    "                    parameters_string = parameters_string[:-1]\n",
    "                    for j in range(num_cvs):\n",
    "                        coeff_string = ''\n",
    "                        for value in tica.singular_vectors_left.T[j]:\n",
    "                            string = str(value)+','\n",
    "                            coeff_string = coeff_string + string\n",
    "                        coeff_string = coeff_string[:-1]\n",
    "                        f.writelines('tica{j}: COMBINE ARG={arg_string} COEFFICIENTS={coeff_string} PARAMETERS={parameters_string} PERIODIC=NO\\n'.format(j=j,arg_string=arg_string,coeff_string=coeff_string,parameters_string=parameters_string))\n",
    "         \n",
    "                    f.writelines(f'PRINT ARG=tica0,tica1 STRIDE=1 FILE=./tica-cv/tica_COLVAR_round{i}_split{split}_chain{chain_ids[chaini]}')\n",
    "                if driver:\n",
    "                    !plumed driver --mf_xtc ./round{i}_unbiased/split_{split}.xtc --plumed ./tica-cv/tica-driver_round{i}_chain{chain_ids[chaini]}.dat\n",
    "    return traj[0].columns,tica.singular_vectors_left.T\n",
    "def cv_projection_2D(round,start,end,seed_num,conf_seed,chain_ids,cv1,cv2,dir='tica-cv',prefix='tica_',seed=True,savefig=False,diff1=True,diff2=True):\n",
    "    CV1 = cv1\n",
    "    CV2 = cv2\n",
    "    for i in range(1,round+1):\n",
    "        if i != 1: \n",
    "            start_num = 0\n",
    "            end_num = seed_num-1\n",
    "        else:\n",
    "            start_num = start\n",
    "            end_num = end\n",
    "        for split in range(start_num,end_num+1):\n",
    "            for chain in chain_ids:\n",
    "                COLVAR = plumed.read_as_pandas(f'./{dir}/{prefix}COLVAR_round{i}_split{split}_chain{chain}')\n",
    "                if diff1:\n",
    "                    cv1 = CV1[:-3]+chain+CV1[-3:]\n",
    "                if diff2:\n",
    "                    cv2 = CV2[:-3]+chain+CV2[-3:]\n",
    "                plt.scatter(COLVAR[f'{cv1}'],COLVAR[f'{cv2}'],alpha=0.3)\n",
    "    if seed:\n",
    "        for i in range(1,round+1):\n",
    "            if i != 1: \n",
    "                start_num = 0\n",
    "                end_num = seed_num-1\n",
    "            else:\n",
    "                start_num = start\n",
    "                end_num = end\n",
    "            for split in range(start_num,end_num+1):\n",
    "                for chain in chain_ids:           \n",
    "                    for k in conf_seed:\n",
    "                        seed_round = k[0]//seed_num+1\n",
    "                        seed_traj = k[0]%seed_num\n",
    "                        if i == seed_round:\n",
    "                            if split == seed_traj+start:\n",
    "                                COLVAR = plumed.read_as_pandas(f'./{dir}/{prefix}COLVAR_round{seed_round}_split{split}_chain{chain}')\n",
    "                                if diff1:\n",
    "                                    cv1 = CV1[:-3]+chain+CV1[-3:]\n",
    "                                if diff2:\n",
    "                                    cv2 = CV2[:-3]+chain+CV2[-3:]\n",
    "                                plt.scatter(COLVAR.iloc[k[1]][f'{cv1}'],COLVAR.iloc[k[1]][f'{cv2}'],c='black')\n",
    "    if CV1 == 'tica0':              \n",
    "        plt.xlabel('TIC1',fontsize=15)\n",
    "    else:\n",
    "        plt.xlabel(f'{CV1}',fontsize=15)\n",
    "    if CV2 == 'tica1':              \n",
    "        plt.ylabel('TIC2',fontsize=15)\n",
    "    else:\n",
    "        plt.ylabel(f'{CV2}',fontsize=15)\n",
    "    if savefig:\n",
    "        plt.savefig(f'./figures/round{round}_ticacv.png',dpi=600,transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "def cv_projection_1D(round,start,end,seed_num,chain_ids,cv='dtotal',dir='tica-cv',prefix='tica_',seed=True,savefig=False,diff=True):\n",
    "    CV = cv\n",
    "    for i in range(1,round+1):\n",
    "        if i != 1: \n",
    "            start_num = 0\n",
    "            end_num = seed_num-1\n",
    "        else:\n",
    "            start_num = start\n",
    "            end_num = end\n",
    "        for split in range(start_num,end_num+1):\n",
    "            for chain in chain_ids:\n",
    "                alpha = 1.0\n",
    "                COLVAR = plumed.read_as_pandas(f'./{dir}/{prefix}COLVAR_round{i}_split{split}_chain{chain}')\n",
    "                if diff:\n",
    "                    cv = CV[:-3]+chain+CV[-3:]\n",
    "                plt.plot(COLVAR['time']/20,COLVAR[f'{cv}'],alpha=alpha)\n",
    "    plt.xlabel('MD Time (ns)',fontsize=15)\n",
    "    if cv == 'dtotal':\n",
    "        plt.ylabel('Distance (nm)',fontsize=15)\n",
    "    else:\n",
    "        plt.ylabel(f'{CV}',fontsize=15)\n",
    "    if savefig:\n",
    "        plt.xlim(0,50)\n",
    "        plt.savefig(f'./figures/round{round}_{CV}.png',dpi=600,transparent=True)       \n",
    "    plt.show()\n",
    "\n",
    "def interpret_cv(arg_string,coeff_string,num_cvs,savefig=False):\n",
    "    coeff = []\n",
    "    if type(arg_string) is not list:\n",
    "        arg = arg_string.tolist()\n",
    "    else:\n",
    "        arg = arg_string\n",
    "    coeff_string = coeff_string\n",
    "    coeff = coeff_string.tolist()\n",
    "    for i in range(num_cvs):\n",
    "        coeff_toprint = []\n",
    "        arg_toprint = []\n",
    "        plt.plot(figsize=(6,6))\n",
    "        zip_lists = list(zip(coeff[i],arg))\n",
    "        zip_lists.sort(key=lambda x:abs(x[0]),reverse=True)\n",
    "        coeff_toprint, arg_toprint = zip(*zip_lists)\n",
    "        coeff_toprint = list(coeff_toprint)[:8]\n",
    "        arg_toprint = list(arg_toprint)[:8]\n",
    "        print(arg_toprint)                \n",
    "        plt.bar(arg_toprint,coeff_toprint)\n",
    "        plt.title(f'TIC {i+1}',fontsize=16)\n",
    "        plt.xlabel('Components',fontsize=16)\n",
    "        plt.ylabel('Weights',fontsize=16)\n",
    "        plt.xticks(range(len(arg_toprint)),rotation=45,fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        if savefig:\n",
    "            plt.savefig(f'./figures/TIC {i+1}.png',dpi=600,transparent=True)\n",
    "        plt.show()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55100152",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tica_its(tica_its_lagtimes,dim,var_cutoff,False,n_its,round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b839227-91c4-464d-a548-514179ee227a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Perform tICA\n",
    "data,traj,data_supp = read_features(round,start,end,seed_num,chain_ids,tica_lagtime,supplement=True)       \n",
    "tica,tica_output,tica_output_concat,tica_output_supp = run_TICA(data,data_supp,tica_lagtime,dim,var_cutoff)\n",
    "# K-means clustering\n",
    "n_microstates = calculate_nmicro(tica_output_concat)\n",
    "assignments,assignments_concat,assignments_supp = run_kmeans(tica_output,tica_output_concat,tica_output_supp,n_microstates,runtICA_njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508d06a-a7fb-4861-990e-a24bf30538f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_its(its_lagtimes,n_its,round)\n",
    "counts,msm = build_MSM(msm_lagtime,assignments,assignments_supp)\n",
    "pcca = run_PCCA(msm,n_metastable_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da332e91-4342-4e4e-b5af-194544679253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed generation\n",
    "n_macro_disconnected,pcca_assignments,stationary_distribution = fix_disconnected(counts,n_microstates,msm,pcca)\n",
    "seed_idx = count_macro(seed_num,n_macro_disconnected,pcca_assignments,assignments_concat,round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62015083-1cda-47bd-bc00-26b32cb4d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files and Run adaptive MD\n",
    "round,conf_seed = write_gmxfile(round,start,end,seed_num,whole_gro,assignments,seed_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4731c-399e-43f1-ac4f-020a6fdb74fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arg_string,coeff_string = tica_cv_print(['./CV/round1_split40_chainA.dat','./CV/round1_split40_chainB.dat','./CV/round1_split40_chainC.dat','./CV/round1_split40_chainD.dat'],traj,tica,num_cvs,chain_ids,round-1,start,end,seed_num,True)\n",
    "cv_projection_2D(round-1,start,end,seed_num,[],chain_ids,cv1='tica0',cv2='tica1',dir='./tica-cv',prefix='tica_',seed=False,savefig=True,diff1=False,diff2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531b10b-3c56-4e18-b545-398af5c69224",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_cv(arg_string,coeff_string,num_cvs,savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3b12e-0c2b-46cf-a748-1d4c8ec297a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_projection_1D(round-1,start,end,seed_num,[],chain_ids,cv='dtotal',dir='CV',prefix='',savefig=True,diff=False,seed=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
