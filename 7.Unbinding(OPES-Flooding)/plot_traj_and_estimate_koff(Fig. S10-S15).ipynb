{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdbcbf-5bdb-4efa-bd60-6b35563dda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plumed\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from deeptime.decomposition import TICA\n",
    "from deeptime.covariance import KoopmanWeightingEstimator\n",
    "from deeptime.clustering import MiniBatchKMeans\n",
    "from deeptime.markov import TransitionCountEstimator\n",
    "from deeptime.markov.msm import MaximumLikelihoodMSM\n",
    "from copy import deepcopy\n",
    "from numpy.random import multinomial\n",
    "\n",
    "import math\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.optimize import curve_fit\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4563a48",
   "metadata": {},
   "source": [
    "Initialization Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08858ad8",
   "metadata": {},
   "source": [
    " Cal FES Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizarion and analysis functions    \n",
    "def cal_OPES_1DFES(cv,dir,sigma=None,block=10,min_slope_index=None):\n",
    "    if sigma == None:\n",
    "        KERNEL = plumed.read_as_pandas(f'../../FES/{dir}/KERNELS')\n",
    "        sigma = KERNEL.loc[:,f'sigma_{cv}'].iloc[-1]\n",
    "    !python /root/FES_from_Reweighting.py -f ../../FES/{dir}/OPES-COLVAR -o ../../FES/{dir}/1D_FES -s {sigma}  --temp 310 --cv {cv} --bias opes.bias #--stride 100\n",
    "    FES = plumed.read_as_pandas(f'../../FES/{dir}/1D_FES') \n",
    "    COLVAR = plumed.read_as_pandas(f'../../FES/{dir}/OPES-COLVAR')\n",
    "    x_start = COLVAR[f'{cv}'].iloc[0]\n",
    "    if x_start < 0:\n",
    "        x_start = x_start + 2*math.pi\n",
    "    x_start = x_start/math.pi*180\n",
    "\n",
    "    !python /root/FES_from_Reweighting.py -f ../../FES/{dir}/OPES-COLVAR -o ../../FES/{dir}/1D_FES_{block} -s {sigma}  --temp 310 --cv {cv} --bias opes.bias --blocks {block}\n",
    "    block_number = np.around(len(COLVAR[f'{cv}'])/block)\n",
    "    error = pd.read_csv(f'../../FES/{dir}/1D_FES_{block}_log',sep='\\t',header=None)\n",
    "        \n",
    "    block_error = float(error.iloc[:,2])\n",
    "    print(f'block numbers are {block_number}')\n",
    "    print(f'block errors are {block_error}')\n",
    "    ERROR = plumed.read_as_pandas(f'../../FES/{dir}/1D_FES_{block}') \n",
    "\n",
    "    plot_FES = []\n",
    "    plot_CV = []\n",
    "    plot_uncertainty = []\n",
    "    shift_FES = []\n",
    "    shift_CV = []\n",
    "    shift_uncertainty = []\n",
    "    for i in range(len(ERROR[f'{cv}'])):\n",
    "        if ERROR[f'{cv}'][i] < 0:\n",
    "            ERROR[f'{cv}'][i] = ERROR[f'{cv}'][i]+2*math.pi\n",
    "            shift_CV.append(ERROR[f'{cv}'][i]/math.pi*180)\n",
    "            shift_FES.append(ERROR['file.free'][i])\n",
    "            shift_uncertainty.append(ERROR['uncertainty'][i])\n",
    "        else:\n",
    "            plot_CV.append(ERROR[f'{cv}'][i]/math.pi*180)\n",
    "            plot_FES.append(ERROR['file.free'][i])\n",
    "            plot_uncertainty.append(ERROR['uncertainty'][i])\n",
    "    plot_CV = plot_CV+shift_CV\n",
    "    plot_FES = plot_FES + shift_FES\n",
    "    plot_FES = np.array(plot_FES)/4.184\n",
    "    plot_uncertainty = plot_uncertainty + shift_uncertainty\n",
    "    plot_uncertainty = np.array(plot_uncertainty)/4.184\n",
    "\n",
    "    !rm ../../FES/{dir}/1D_FES_*_*\n",
    "    return plot_CV,plot_FES,plot_uncertainty,x_start\n",
    "def plot_allFES(plot_CV,plot_FES,plot_uncertainty,x_start):\n",
    "    colors = ['C0','C1','C2']\n",
    "    plt.plot(figsize=(10,6))\n",
    "    for i in range(len(plot_CV)):\n",
    "        plt.plot(plot_CV[i],plot_FES[i],label=['MhOR5-EOL','MhOR5-DEET',r'MhOR5$_{apo}$'][i])\n",
    "        plt.fill_between(plot_CV[i],np.array(plot_FES[i])-np.array(plot_uncertainty[i]),np.array(plot_FES[i])+np.array(plot_uncertainty[i]),alpha=0.5)\n",
    "        # plt.vlines(x_start[i],ymin=0,ymax=80,linewidth=1,color=colors[i],alpha=0.8,linestyle='--')\n",
    "    plt.xlabel(r'$\\chi_2^{W158}$ (degree)',fontsize=20)\n",
    "    plt.ylabel('Free Energy (kcal/mol)',fontsize=20)\n",
    "    plt.ylim(0,20)\n",
    "    plt.xlim(0,360)\n",
    "    plt.xticks(np.arange(0,370,60))\n",
    "    plt.yticks(np.arange(0,21,5))\n",
    "    plt.axvspan(np.min(x_start), np.max(x_start), color='gray', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../../FES/chi21D_FES_all.pdf',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a70510",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplot_CV_1,Aplot_FES_1,Aplot_uncertainty_1,Ax_start_1 = cal_OPES_1DFES('torsion_chi1-162',dir='APO',sigma=0.0628,min_slope_index=5,block = 10)\n",
    "Dplot_CV_1,Dplot_FES_1,Dplot_uncertainty_1,Dx_start_1 = cal_OPES_1DFES('torsion_chi1-162',dir='DEET',sigma=0.0628,min_slope_index=5,block = 10)\n",
    "Eplot_CV_1,Eplot_FES_1,Eplot_uncertainty_1,E_xstart_1 = cal_OPES_1DFES('torsion_chi1-162',dir='EOL',sigma=0.0628,min_slope_index=5,block = 10)\n",
    "plot_CV_1 = [Eplot_CV_1,Dplot_CV_1,Aplot_CV_1]\n",
    "plot_FES_1 = [Eplot_FES_1,Dplot_FES_1,Aplot_FES_1]\n",
    "plot_uncertainty_1 = [Eplot_uncertainty_1,Dplot_uncertainty_1,Aplot_uncertainty_1]\n",
    "x_start_1 = [E_xstart_1,Dx_start_1,Ax_start_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplot_CV_2,Aplot_FES_2,Aplot_uncertainty_2,Ax_start_2 = cal_OPES_1DFES('torsion_chi2-162',sigma=0.0628,dir='APO',min_slope_index=5,block=10)\n",
    "Dplot_CV_2,Dplot_FES_2,Dplot_uncertainty_2,Dx_start_2 = cal_OPES_1DFES('torsion_chi2-162',sigma=0.0628,dir='DEET',min_slope_index=5,block=10)\n",
    "Eplot_CV_2,Eplot_FES_2,Eplot_uncertainty_2,E_xstart_2 = cal_OPES_1DFES('torsion_chi2-162',sigma=0.0628,dir='EOL',min_slope_index=5,block=10)\n",
    "plot_CV_2 = [Eplot_CV_2,Dplot_CV_2,Aplot_CV_2]\n",
    "plot_FES_2 = [Eplot_FES_2,Dplot_FES_2,Aplot_FES_2]\n",
    "plot_uncertainty_2 = [Eplot_uncertainty_2,Dplot_uncertainty_2,Aplot_uncertainty_2]\n",
    "x_start_2 = [E_xstart_2,Dx_start_2,Ax_start_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38022dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allFES(plot_CV_1,plot_FES_1,plot_uncertainty_1,x_start_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allFES(plot_CV_2,plot_FES_2,plot_uncertainty_2,x_start_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f1d25",
   "metadata": {},
   "source": [
    "Cal Kinetics Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_kinetics(dir,barrier):\n",
    "    T = 310 #Temperature in K\n",
    "    dt = 200 #The frequency at which colvars is deposited (in ps)\n",
    "    time_unit = 10**12 #in ps\n",
    "    kT = 0.008314462618*T #in kJ/mol\n",
    "\n",
    "    average_accelerate = []\n",
    "\n",
    "    COLVAR = plumed.read_as_pandas(f'./{dir}/OPES-COLVAR')\n",
    "    bias = np.array(COLVAR.loc[:,'opes.bias'])\n",
    "    dtotal = np.array(COLVAR.loc[:,'dtotal'])\n",
    "    time = np.array(COLVAR.loc[:,'time'])\n",
    "\n",
    "    f1 = open(f'./{dir}/time','w')\n",
    "    print('simulation_time, CV, accelerate_time(ns),accumulate_accelerate_time(ns)',file=f1)\n",
    "\n",
    "    accumulate_accelerate = 0\n",
    "    accumulate_time = 0\n",
    "    for j in range(len(time)):\n",
    "        accumulate_accelerate += np.exp((bias[j]+barrier)/kT)\n",
    "        average_accelerate.append(accumulate_accelerate/(j+1))\n",
    "        accelerate = np.exp(((bias[j]+barrier)/kT))\n",
    "        accumulate_time += dt*accelerate\n",
    "\n",
    "        print(time[j],dtotal[j],accumulate_time/time_unit,(time[j]/time_unit)*(accumulate_accelerate/(j+1)),file=f1)\n",
    "        if j == len(time)-1:\n",
    "            final_unrescaled_time = time[j]\n",
    "            final_rescaled_time = accumulate_time/time_unit\n",
    "            final_time_print = f'{time[j]},{dtotal[j]},{accumulate_time/time_unit},{(time[j]/time_unit)*(accumulate_accelerate/(j+1))}\\n'\n",
    "            average_accelerate_print= accumulate_accelerate/(j+1)\n",
    "\n",
    "    f1.close()\n",
    "    print(f'the off time of {dir} is: {accumulate_time/time_unit} (s) = {accumulate_time/time_unit*10**3} ms = {accumulate_time/time_unit*10**6} us')\n",
    "    print(f'now the average accelerate factor is {average_accelerate_print}')\n",
    "    \n",
    "    plt.plot(time/(10**3),average_accelerate)\n",
    "\n",
    "    plt.xlabel('MD simulation time (ns)')\n",
    "    plt.ylabel('Average Accelerate Factor')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "    return final_time_print,final_rescaled_time,final_unrescaled_time\n",
    "def evaluate_kinetics(final_time_print,final_rescaled_time,final_unrescaled_time,title,bootstrap=True,boots=50):\n",
    "    with open(f'./{title}-all-time.dat','w') as f:\n",
    "        for i in final_time_print:\n",
    "            f.writelines(i)\n",
    "    final_rescaled_time = np.array(final_rescaled_time)\n",
    "    final_unrescaled_time = np.array(final_unrescaled_time)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, sharey=True)\n",
    "\n",
    "    def func(x,tau):\n",
    "        return 1-np.exp(-x/tau)\n",
    "    with open(f'./{title}-results-ks.dat','w') as out:\n",
    "        out.write('Results-KS:\\n')\n",
    "\n",
    "    def KStest(final_rescaled_time):\n",
    "        for i in range(len(final_rescaled_time)):\n",
    "        \n",
    "            mint = min(final_rescaled_time/100)\n",
    "            maxt = max(final_rescaled_time*100)\n",
    "        \n",
    "            ###########################\n",
    "            # for numerical stability we divide by the mean\n",
    "            mu = np.mean(final_rescaled_time)\n",
    "            sigma = np.std(final_rescaled_time)\n",
    "            t_m = np.median(final_rescaled_time)\n",
    "        \n",
    "            x=final_rescaled_time/mu\n",
    "            # now compute empirical CDF\n",
    "            ecdf = ECDF(x)\n",
    "            x1 = np.logspace(np.log10(mint/mu), np.log10(maxt/mu),10000)\n",
    "            y1 = ecdf(x1)\n",
    "            # fit to theoretical CDF to obtain tau\n",
    "            popt,pcov = curve_fit(func,x1,y1)\n",
    "            tau=popt[0]\n",
    "            yfit=func(x1,tau)\n",
    "        \n",
    "            x2 = np.random.gamma(1,tau,10000000)\n",
    "            st,pvalue = ks_2samp(x2,x)\n",
    "            pvalue = '{:.10f}'.format(pvalue)\n",
    "            str_tau=str(tau*mu)[:4]\n",
    "            str_p=str(pvalue)[:4]\n",
    "            \n",
    "            ax.step(x1*mu, y1,'k-',lw=1. )\n",
    "            ax.plot(x1*mu,yfit,'b-',lw=3.)\n",
    "            ax.set_xscale('log')\n",
    "            return float(tau*mu*1E+3),float(pvalue)\n",
    "    tau,pvalue = KStest(final_rescaled_time)\n",
    "    if bootstrap:\n",
    "        bootstraps = []\n",
    "        taus = []\n",
    "        ps = []\n",
    "        for boot in range(boots):\n",
    "            bootstraps.append(np.array(random.choices(final_rescaled_time,k=len(final_rescaled_time))))\n",
    "        for bootstrap_s in bootstraps:\n",
    "            taus.append(KStest(bootstrap_s)[0])\n",
    "            ps.append(KStest(bootstrap_s)[1])\n",
    "\n",
    "        tau_std = np.std(taus)\n",
    "        p_std = np.std(ps)\n",
    "\n",
    "    plt.xlabel('Time (s)',fontsize=16)\n",
    "    plt.ylabel('Cumulative Probability',fontsize=16)\n",
    "    plt.title(title,fontsize=16)\n",
    "    # plt.xticks(fontsize=16)\n",
    "    # plt.yticks(fontsize=16)\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0,1.005)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./{title}KS-test.png', bbox_inches='tight', dpi=300,transparent=True)\n",
    "    plt.show()\n",
    "    return tau,pvalue,tau_std,p_std\n",
    "\n",
    "def plot_trajs(dir_list,cv1,cv2,plot_CV,plot_FES,plot_uncertainty):\n",
    "    length = max(len(dir_list[0]),len(dir_list[1]))+1\n",
    "    fig,axs = plt.subplots(length,2,figsize=(10,1*length))\n",
    "    for j, dirs in enumerate(dir_list):\n",
    "        for k, dir in enumerate(dirs):\n",
    "\n",
    "            COLVAR = plumed.read_as_pandas(f'./{dir}/OPES-COLVAR')\n",
    "            tica0 = (COLVAR.loc[:,f'{cv1}'].iloc[::1]/math.pi*180).tolist()\n",
    "            tica1 = (COLVAR.loc[:,f'{cv2}'].iloc[::1]).tolist()\n",
    "            shift_tica0 = []\n",
    "            for i in tica0:\n",
    "                if i < 0:\n",
    "                    shift_tica0.append(i+360)\n",
    "                else:\n",
    "                    shift_tica0.append(i)\n",
    "            tica0 = shift_tica0\n",
    "\n",
    "            points = np.array([tica0,tica1]).T.reshape(-1,1,2)\n",
    "            segments = np.concatenate([points[:-1],points[1:]],axis=1)\n",
    "            for segment in segments:\n",
    "                if  segment[1,1] > 1.2 and segment[0,1] > 1.2:\n",
    "                    axs[k+1,j].plot(segment[:,0],segment[:,1],color='C2')\n",
    "                elif np.mean(segment[:,1]) > 0.9:\n",
    "                    axs[k+1,j].plot(segment[:,0],segment[:,1],color='C1')\n",
    "                elif segment[0,1] < 0.9 and segment[1,1] > 1.2 or segment[0,1] > 1.2 and segment[1,1] < 0.9:\n",
    "                    axs[k+1,j].plot(segment[:,0],segment[:,1],color='C1')\n",
    "                else:\n",
    "                    axs[k+1,j].plot(segment[:,0],segment[:,1],color='C0')\n",
    "            axs[k+1,j].set_ylim(0,2.5)\n",
    "            if j == 0:\n",
    "                axs[k+1,j].set_ylabel(r'$d_{l-p}$ (nm)',fontsize=10)\n",
    "            if j != 0:\n",
    "                axs[k+1,j].set_yticks([])\n",
    "\n",
    "            axs[k+1,j].set_xlim(0,360)\n",
    "            if k + 1 == len(dirs):\n",
    "                axs[k+1,j].set_xticks(np.arange(0,361,120))\n",
    "            else:\n",
    "                axs[k+1,j].set_xticks([])\n",
    "\n",
    "            axs[k+1,j].axvline(110,color='black',linestyle='--',alpha=0.3)\n",
    "            axs[k+1,j].axvline(240,color='black',linestyle='--',alpha=0.3)\n",
    "\n",
    "            axs[k+1,j].axhline(0.9,color='black',linestyle='--',alpha=0.3)\n",
    "\n",
    "    axs[0,0].plot(plot_CV,plot_FES,color='C1')\n",
    "    axs[0,0].fill_between(plot_CV,np.array(plot_FES)-np.array(plot_uncertainty),np.array(plot_FES)+np.array(plot_uncertainty),color='C0',alpha=0.3)\n",
    "    axs[0,0].set_title('Top',fontsize=16)\n",
    "    axs[0,0].axvline(110,color='black',linestyle='--',alpha=0.3)\n",
    "    axs[0,0].axvline(240,color='black',linestyle='--',alpha=0.3)\n",
    "    axs[0,0].set_xticks([])\n",
    "\n",
    "    axs[0,1].plot(plot_CV,plot_FES,color='C1')\n",
    "    axs[0,1].fill_between(plot_CV,np.array(plot_FES)-np.array(plot_uncertainty),np.array(plot_FES)+np.array(plot_uncertainty),color='C0',alpha=0.3)\n",
    "    axs[0,1].set_title('Side',fontsize=16)\n",
    "    axs[0,1].axvline(110,color='black',linestyle='--',alpha=0.3)\n",
    "    axs[0,1].axvline(240,color='black',linestyle='--',alpha=0.3)\n",
    "    axs[0,1].set_xticks([])\n",
    "    axs[0,1].set_yticks([])\n",
    "\n",
    "    axs[-1,0].set_xlabel(r'$\\chi_1^{W158}$ (degree)',fontsize=16)\n",
    "    axs[-1,1].set_xlabel(r'$\\chi_1^{W158}$ (degree)',fontsize=16)\n",
    "\n",
    "    for j, dirs in enumerate(dir_list):\n",
    "        n_valid = len(dirs)\n",
    "        for i in range(n_valid + 1, length):\n",
    "            axs[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'EOLtrajs{cv1}.pdf',dpi=300,transparent=True)\n",
    "    plt.show()\n",
    "def cal_koff(toff,tstd):\n",
    "    koff = 1000/toff\n",
    "    koff_std = 1000*tstd/(toff**2)\n",
    "    return koff,koff_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df123525",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_list = ['4','16','14','8','18','2','7','6']\n",
    "side_list = ['3','12','19','11','1','9','13','10','17','5','15','20']\n",
    "out_list = [top_list,side_list]\n",
    "total_list = [top_list,side_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajs(total_list,'chi1-162','dtotal',Eplot_CV_1,Eplot_FES_1,Eplot_uncertainty_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd891b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajs(total_list,'chi2-162','dtotal',Eplot_CV_2,Eplot_FES_2,Eplot_uncertainty_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7370a0-9492-4a6e-8bef-ce5b63911b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_final_time_print_list = []\n",
    "top_final_rescaled_time_list = []\n",
    "top_final_unrescaled_time_list = []\n",
    "side_final_time_print_list = []\n",
    "side_final_rescaled_time_list = []\n",
    "side_final_unrescaled_time_list = []\n",
    "no_final_time_print_list = []\n",
    "no_final_rescaled_time_list = []\n",
    "no_final_unrescaled_time_list = []\n",
    "for i in top_list:\n",
    "    final_time_print,final_rescaled_time,final_unrescaled_time = cal_kinetics(i,20)\n",
    "    top_final_time_print_list.append(final_time_print)\n",
    "    top_final_rescaled_time_list.append(final_rescaled_time)\n",
    "    top_final_unrescaled_time_list.append(final_unrescaled_time)\n",
    "for i in side_list:\n",
    "    final_time_print,final_rescaled_time,final_unrescaled_time = cal_kinetics(i,20)\n",
    "    side_final_time_print_list.append(final_time_print)\n",
    "    side_final_rescaled_time_list.append(final_rescaled_time)\n",
    "    side_final_unrescaled_time_list.append(final_unrescaled_time)\n",
    "\n",
    "total_final_time_print_list = top_final_time_print_list + side_final_time_print_list \n",
    "total_final_rescaled_time_list = top_final_rescaled_time_list + side_final_rescaled_time_list \n",
    "total_final_unrescaled_time_list = top_final_unrescaled_time_list + side_final_unrescaled_time_list \n",
    "print(len(total_final_time_print_list))\n",
    "print(len(total_final_rescaled_time_list))\n",
    "print(len(total_final_unrescaled_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9ae31-3336-4303-8a1a-bddd308331b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toffp2,pp2,tstdp2,pstdp2 = evaluate_kinetics(side_final_time_print_list,side_final_rescaled_time_list,side_final_unrescaled_time_list,title='P2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'toff of P2 is {toffp2} +/- {tstdp2}')\n",
    "print(f'p value of P2 is {pp2} +/- {pstdp2}')\n",
    "koffp2,koff_std_p2 = cal_koff(toffp2,tstdp2)\n",
    "print(f'koff of P2 is {koffp2} +/- {koff_std_p2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21243441",
   "metadata": {},
   "outputs": [],
   "source": [
    "toffp1,pp1,tstdp1,pstdp1 = evaluate_kinetics(top_final_time_print_list,top_final_rescaled_time_list,top_final_unrescaled_time_list,title='P1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda194e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'toff of P1 is {toffp1} +/- {tstdp1}')\n",
    "print(f'p value of P1 is {pp1} +/- {pstdp1}')\n",
    "koffp1,koff_std_p1 = cal_koff(toffp1,tstdp1)\n",
    "print(f'koff of P1 is {koffp1} +/- {koff_std_p1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toffpall,ppall,tstdpall,pstdpall = evaluate_kinetics(total_final_time_print_list,total_final_rescaled_time_list,total_final_unrescaled_time_list,title='Pall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'toff of Pall is {toffpall} +/- {tstdpall}')\n",
    "print(f'p value of Pall is {ppall} +/- {pstdpall}')\n",
    "koffpall,koff_std_pall = cal_koff(toffpall,tstdpall)\n",
    "print(f'koff of Pall is {koffpall} +/- {koff_std_pall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25741d90",
   "metadata": {},
   "source": [
    "MLE for DEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82584f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLE estimation\n",
    "out_final_rescaled_time_list = top_final_rescaled_time_list + side_final_rescaled_time_list\n",
    "taumle = np.sum(total_final_rescaled_time_list*1000)/len(out_final_rescaled_time_list)\n",
    "taumle_std = np.sum(total_final_rescaled_time_list*1000)/(len(out_final_rescaled_time_list)**1.5)\n",
    "koffmle,koff_std_mle = cal_koff(taumle,taumle_std)\n",
    "\n",
    "print(f'koff of MLE is {koffmle} +/- {koff_std_mle}')\n",
    "print(f'tau of MLE is {taumle} +/- {taumle_std}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
